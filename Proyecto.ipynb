{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import math\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model\n",
    "\n",
    "py.plotly.tools.set_credentials_file(username='mpeyrotc', api_key='pNScWhvJN9woL3frF4Vd')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Components Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R3P = pd.ExcelFile(\"R3P Q2 Mayo (ADV).xlsx\")\n",
    "R3P_1 = R3P.parse(\"R3P Q2 Mayo\")\n",
    "\n",
    "R3P_1 = R3P_1.ix[4:,3:31]\n",
    "\n",
    "R3P_1.columns=['Weekday', 'Time', 'Act. WPs', 'Dia.WPs', 'RFC WPs', 'CPU Usr',\n",
    "            'CPU Sys', 'CPU Idle', 'Paging in', 'Paging out', 'Free Mem.', \n",
    "            'EM alloc.', 'EM attach.', 'Em global', 'Heap Memor', 'Private Modes',\n",
    "            'Paging Mem', 'Roll Mem', 'Logins', 'Sessions', '# Pasos Dialogo',\n",
    "            'Resp. Time (Total)', 'CPU (Total)', 'CPU (Prom)', 'BD (Total)', \n",
    "            'BD (Prom)', 'Response Time (Prom)', 'Label']\n",
    "\n",
    "R3P_1.dropna(how=\"all\", inplace=True)\n",
    "R3P_1['Time'] = R3P_1['Time'].astype(str).apply(lambda x: str(x[0]) + str(x[1]))\n",
    "\n",
    "X = R3P_1.ix[:,0:-1]\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov_mat = np.cov(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "#print('Eigenvectors \\n%s' %eig_vecs[0])\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "#print('\\nCovariance \\n%s' %cov_mat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ev in eig_vecs:\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "print('Everything ok!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "#print('Eigenvalues in descending order:')\n",
    "#for i in eig_pairs:\n",
    "#    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    plt.bar(range(27), var_exp, alpha=0.5, align='center',\n",
    "            label='individual explained variance')\n",
    "    plt.step(range(27), cum_var_exp, where='mid',\n",
    "             label='cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PCAs = pd.ExcelFile(\"PCAs.xlsx\")\n",
    "F1F2 = PCAs.parse(\"F1F2\")\n",
    "\n",
    "F1F2_X = F1F2.ix[104:130,1:28]\n",
    "\n",
    "columns = []\n",
    "for i in xrange(0,27):\n",
    "    columns.append(\"F\" + str(i + 1))\n",
    "\n",
    "F1F2_X.columns=columns\n",
    "\n",
    "F1F2_y = F1F2.ix[104:130,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components F1 and F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(7.5, 7.5))\n",
    "    plt.scatter(F1F2_X.T.values[0], F1F2_X.T.values[1], c=\"Orange\")\n",
    "    plt.ylabel('F2 (13.40%)')\n",
    "    plt.xlabel('F1 (35.83%)')\n",
    "    plt.tight_layout()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-1,1])\n",
    "    axes.set_ylim([-1,1])\n",
    "    \n",
    "    discriminators = [26, 17, 11, 20, 13, 18, 19, 16, 5]\n",
    "    colors = sns.color_palette(\"Set1\", n_colors=len(discriminators), desat=.5)\n",
    "    \n",
    "    for x,y,closest,label in zip(F1F2_X.T.values[0], F1F2_X.T.values[1], range(0,27), F1F2_y.T.values[0]):\n",
    "        plt.plot([0,x], [0, y], '-', linewidth=0.3, c=\"Green\")\n",
    "        if closest not in  discriminators:\n",
    "            plt.annotate(label, xy=(x, y), xytext=(x, y + 0.01))\n",
    "\n",
    "    legend = []\n",
    "    for index, color in zip(discriminators, colors.as_hex()):\n",
    "        plt.scatter(F1F2_X.T.values[0][index], F1F2_X.T.values[1][index], c=color)\n",
    "        legend.append(mpatches.Patch(color=color, label=F1F2_y.T.values[0][index]))\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., handles=legend)\n",
    "    \n",
    "    plt.plot([-1, 1], [0, 0], '--', linewidth=1, c=\"Black\")\n",
    "    plt.plot([0, 0], [-1, 1], '--', linewidth=1, c=\"Black\")\n",
    "    circle = plt.Circle((0, 0), 1, color='Black', fill=False)\n",
    "    plt.gcf().gca().add_artist(circle)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #mpl_fig1 = plt.gcf()\n",
    "    #py_fig1 = tls.mpl_to_plotly(mpl_fig1)\n",
    "    #py.iplot(py_fig1, filename='pcas')\n",
    "    #tls.embed(\"https://plot.ly/~mpeyrotc/0\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components F1 and F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(7.5, 7.5))\n",
    "    \n",
    "    plt.scatter(F1F2_X.T.values[0], F1F2_X.T.values[2], c=\"Orange\")\n",
    "    plt.ylabel('F3 (6.62%)')\n",
    "    plt.xlabel('F1 (35.83%)')\n",
    "    plt.tight_layout()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-1,1])\n",
    "    axes.set_ylim([-1,1])\n",
    "    \n",
    "    discriminators = [9, 3, 26, 17, 11, 18, 13, 19, 16]\n",
    "    colors = sns.color_palette(\"Set1\", n_colors=len(discriminators), desat=.5)\n",
    "    \n",
    "    for x,y,closest,label in zip(F1F2_X.T.values[0], F1F2_X.T.values[2], range(0,27), F1F2_y.T.values[0]):\n",
    "        plt.plot([0,x], [0, y], '-', linewidth=0.3, c=\"Green\")\n",
    "        if closest not in  discriminators:\n",
    "            plt.annotate(label, xy=(x, y), xytext=(x, y + 0.01))\n",
    "            \n",
    "    legend = []\n",
    "    for index, color in zip(discriminators, colors.as_hex()):\n",
    "        plt.scatter(F1F2_X.T.values[0][index], F1F2_X.T.values[2][index], c=color)\n",
    "        legend.append(mpatches.Patch(color=color, label=F1F2_y.T.values[0][index]))\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., handles=legend)\n",
    "    \n",
    "    plt.plot([-1, 1], [0, 0], '--', linewidth=1, c=\"Black\")\n",
    "    plt.plot([0, 0], [-1, 1], '--', linewidth=1, c=\"Black\")\n",
    "    circle = plt.Circle((0, 0), 1, color='Black', fill=False)\n",
    "    plt.gcf().gca().add_artist(circle)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components F2 and F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(7.5, 7.5))\n",
    "    plt.scatter(F1F2_X.T.values[1], F1F2_X.T.values[2], c=\"Orange\")\n",
    "    plt.ylabel('F3 (6.62%)')\n",
    "    plt.xlabel('F2 (13.40%)')\n",
    "    plt.tight_layout()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-1,1])\n",
    "    axes.set_ylim([-1,1])\n",
    "    \n",
    "    discriminators = [11, 19, 18, 17, 16, 13, 9]\n",
    "    colors = sns.color_palette(\"Set1\", n_colors=len(discriminators), desat=.5)\n",
    "    \n",
    "    for x,y,closest,label in zip(F1F2_X.T.values[1], F1F2_X.T.values[2], range(0,27), F1F2_y.T.values[0]):\n",
    "        plt.plot([0,x], [0, y], '-', linewidth=0.3, c=\"Green\")\n",
    "        if closest not in  discriminators:\n",
    "            plt.annotate(label, xy=(x, y), xytext=(x, y + 0.01))\n",
    "            \n",
    "    legend = []\n",
    "    for index, color in zip(discriminators, colors.as_hex()):\n",
    "        plt.scatter(F1F2_X.T.values[1][index], F1F2_X.T.values[2][index], c=color)\n",
    "        legend.append(mpatches.Patch(color=color, label=F1F2_y.T.values[0][index]))\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., handles=legend)\n",
    "    \n",
    "    plt.plot([-1, 1], [0, 0], '--', linewidth=1, c=\"Black\")\n",
    "    plt.plot([0, 0], [-1, 1], '--', linewidth=1, c=\"Black\")\n",
    "    circle = plt.Circle((0, 0), 1, color='Black', fill=False)\n",
    "    plt.gcf().gca().add_artist(circle)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecció de variables críticas y reducción de dimensiones\n",
    "\n",
    "Basado en los resultados eobtenidos en las gráficas anteriores, se determinó que las siguientes variables están correlacionadas a Response Time (promedio) de acuerdo al componente principal F1F2:\n",
    "\n",
    "1. BD (Prom)\n",
    "2. CPU(Prom)\n",
    "3. Private modes\n",
    "4. RFC WPs\n",
    "5. Time\n",
    "\n",
    "De la misma forma, se determinó que por el componente F1 y F3 las siguientes variables también se correlacionan con response time (promedio):\n",
    "\n",
    "6. CPU Idle\n",
    "7. CPU Usr\n",
    "\n",
    "A continuación se muestran las gráficas de comportamiento de cada uno con respecto a response time. Las gráficas naranjas representan una relación visible de relevancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    plt.subplot(4, 3, 1)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,100000])\n",
    "    axes.set_ylim([0,35000])\n",
    "    plt.scatter(R3P_1[\"Response Time (Prom)\"].T, R3P_1[\"BD (Prom)\"].T, c=\"Orange\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('DB (Average) [ms]')\n",
    "    \n",
    "    plt.subplot(4, 3, 2)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,100000])\n",
    "    axes.set_ylim([0,35000])\n",
    "    plt.scatter(R3P_1[\"Response Time (Prom)\"].T, R3P_1[\"CPU (Prom)\"].T, c=\"Orange\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('CPU (Average) [ms]')\n",
    "    \n",
    "    plt.subplot(4, 3, 3)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,100000])\n",
    "    axes.set_ylim([0,9])\n",
    "    plt.scatter(R3P_1[\"Response Time (Prom)\"].T, R3P_1[\"Private Modes\"].T, c=\"Blue\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('Private Modes [Number]')\n",
    "    \n",
    "    plt.subplot(4, 3, 4)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,100000])\n",
    "    axes.set_ylim([0,40])\n",
    "    plt.scatter(R3P_1[\"Response Time (Prom)\"].T, R3P_1[\"RFC WPs\"].T, c=\"Blue\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('RFC WPs [Number]')\n",
    "    \n",
    "    plt.subplot(4, 3, 5)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,100000])\n",
    "    axes.set_ylim([0,23])\n",
    "    plt.scatter(R3P_1[\"Response Time (Prom)\"].T, R3P_1[\"Time\"].T, c=\"Blue\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('Time [hours]')\n",
    "    \n",
    "    plt.subplot(4, 3, 6)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,100000])\n",
    "    axes.set_ylim([0,100])\n",
    "    plt.scatter(R3P_1[\"Response Time (Prom)\"].T, R3P_1[\"CPU Idle\"].T, c=\"Blue\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('CPU Idle [%]')\n",
    "    \n",
    "    plt.subplot(4, 3, 7)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,100000])\n",
    "    axes.set_ylim([0,35])\n",
    "    plt.scatter(R3P_1[\"Response Time (Prom)\"].T, R3P_1[\"CPU Usr\"].T, c=\"Blue\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('CPU Usr [%]')\n",
    "    \n",
    "    response_time = R3P_1[\"Response Time (Prom)\"].apply(math.log10)\n",
    "    cpu_prom = R3P_1[\"CPU (Prom)\"].apply(math.log10)\n",
    "    \n",
    "    plt.subplot(4, 3, 8)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,5])\n",
    "    axes.set_ylim([0,5])\n",
    "    plt.scatter(response_time.T, cpu_prom.T, c=\"Orange\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('CPU (Average) [ms]')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que hemos seleccionado DB (Prom) y CPU(Prom) como variables potenciales para mejorar el rendimiento del sistema, a continueación se proponen funciones matemáticas representativas del comportamiento del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    x = R3P_1.loc[:,\"Response Time (Prom)\"][:, np.newaxis]\n",
    "    y = R3P_1.loc[:,\"BD (Prom)\"]\n",
    "    \n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x, y)\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,100000])\n",
    "    axes.set_ylim([0,35000])\n",
    "    plt.scatter(R3P_1[\"Response Time (Prom)\"].T, R3P_1[\"BD (Prom)\"].T, c=\"Orange\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('DB (Average) [ms]')\n",
    "    plt.plot(x, regr.predict(x), color='blue', linewidth=1)\n",
    "    plt.text(21500, 33000, r'Equation: $y={coef}x+{intercept}$'.format(coef=\"{0:.2f}\".format(regr.coef_[0]), \n",
    "                                                                       intercept=\"{0:.2f}\".format(regr.intercept_)),\n",
    "             fontsize=12, style='italic', bbox={'facecolor':'gray', 'alpha':0.1, 'pad':2})\n",
    "    plt.title(\"Response Time vs. DB (Average)\")\n",
    "\n",
    "    x = R3P_1.loc[:,\"Response Time (Prom)\"][:, np.newaxis]\n",
    "    y = R3P_1.loc[:,\"CPU (Prom)\"]\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x, y)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,100000])\n",
    "    axes.set_ylim([0,35000])\n",
    "    plt.scatter(R3P_1[\"Response Time (Prom)\"].T, R3P_1[\"CPU (Prom)\"].T, c=\"Orange\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('CPU (Average) [ms]')\n",
    "    plt.plot(x, regr.predict(x), color='blue', linewidth=1)\n",
    "    plt.text(21300, 33000, r'Equation: $y={coef}x+{intercept}$'.format(coef=\"{0:.2f}\".format(regr.coef_[0]), \n",
    "                                                                       intercept=\"{0:.2f}\".format(regr.intercept_)),\n",
    "             fontsize=12, style='italic', bbox={'facecolor':'gray', 'alpha':0.1, 'pad':2})\n",
    "    plt.title(\"Response Time vs. CPU (Average)\")\n",
    "    \n",
    "    x = response_time[:, np.newaxis]\n",
    "    y = cpu_prom\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x, y)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,5])\n",
    "    axes.set_ylim([0,5])\n",
    "    plt.scatter(response_time.T, cpu_prom.T, c=\"Orange\")\n",
    "    plt.xlabel('Response Time (Average) [ms]')\n",
    "    plt.ylabel('CPU (Average) [ms]')\n",
    "    plt.plot(x, regr.predict(x), color='blue', linewidth=1)\n",
    "    plt.text(1.5, 4.7, r'Equation: $y={coef}x+{intercept}$'.format(coef=\"{0:.2f}\".format(regr.coef_[0]), \n",
    "                                                                       intercept=\"{0:.2f}\".format(regr.intercept_)),\n",
    "             fontsize=12, style='italic', bbox={'facecolor':'gray', 'alpha':0.1, 'pad':2})\n",
    "    plt.title(\"Response Time vs. CPU (Average) in log scale\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juan Carlos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## B) Análisis estadístico descriptivo\n",
    "\n",
    "Debido a que encontramos no una, sino dos variables críþicas, (BD y CPU), se analizarán ambas, para ver cuál de las dos es más confiable. Se obtendrá la media, varianza, desviación estándar, la simetría y la curtosis para cada una de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"CPU (Prom):\\n\")\n",
    "print \"Media:\\t\\t\\t\", R3P_1[\"CPU (Prom)\"].mean()\n",
    "print \"Varianza:\\t\\t\", R3P_1[\"CPU (Prom)\"].var()\n",
    "print \"Desviación estándar:\\t\", R3P_1[\"CPU (Prom)\"].std()\n",
    "print \"Simetría:\\t\\t\", R3P_1[\"CPU (Prom)\"].skew()\n",
    "print \"Kurtosis:\\t\\t\", R3P_1[\"CPU (Prom)\"].kurtosis()\n",
    "print\n",
    "print(\"BD (Prom):\\n\")\n",
    "print \"Media:\\t\\t\\t\", R3P_1[\"BD (Prom)\"].mean()\n",
    "print \"Varianza:\\t\\t\", R3P_1[\"BD (Prom)\"].var()\n",
    "print \"Desviación estándar:\\t\", R3P_1[\"BD (Prom)\"].std()\n",
    "print \"Simertía:\\t\\t\", R3P_1[\"BD (Prom)\"].skew()\n",
    "print \"Kurtosis:\\t\\t\", R3P_1[\"BD (Prom)\"].kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Se puede notar con facilidad que ambas variables tienen una cola pesada, pues la kurtosis es mayor a 3. En seguida se muestra un histograma de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as p\n",
    "\n",
    "data=R3P_1[\"CPU (Prom)\"]\n",
    "y,binEdges=np.histogram(data,bins=100)\n",
    "bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
    "p.plot(bincenters,y,'-', label=\"CPU (Prom)\")\n",
    "\n",
    "data=R3P_1[\"BD (Prom)\"]\n",
    "y,binEdges=np.histogram(data,bins=100)\n",
    "bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
    "p.plot(bincenters,y,'-', label=\"BD (Prom)\")\n",
    "\n",
    "p.legend(loc='upper right')\n",
    "\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Se puede observar que ambas variables tienen una forma similar a la de una distribución exponencial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## c)\tDeterminación de la normalidad de los datos\n",
    " En seguida se mostrará una comparación de los datos de ambas variables anteriormente analizadas contra la distribución exponencial. Originalmente, la indicación era probarla contra la distribución normal, pero como se vio que tenían comportamientos similares a las exponenciales, se decició comparar contra ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "from scipy.stats import norm\n",
    "\n",
    "expectedValues = pd.Series(range(1 ,R3P_1[\"CPU (Prom)\"].count() + 1)).apply(lambda x: (x - 0.5) / R3P_1[\"CPU (Prom)\"].count()).apply(lambda x: expon.ppf(x))\n",
    "sortedValues = pd.Series(R3P_1[\"CPU (Prom)\"].sort_values()).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Create a trace\n",
    "trace = Scatter(\n",
    "    x = expectedValues,\n",
    "    y = sortedValues,\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "layout = Layout(\n",
    "    title='CPU (Prom)',\n",
    "    xaxis=dict(\n",
    "        title='Valor estándar para cuantil exponencial'\n",
    "        \n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Valor obtenido'\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='Comparación con exponencial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expectedValues = pd.Series(range(1 ,R3P_1[\"BD (Prom)\"].count() + 1)).apply(lambda x: (x - 0.5) / R3P_1[\"BD (Prom)\"].count()).apply(lambda x: expon.ppf(x))\n",
    "sortedValues = pd.Series(R3P_1[\"BD (Prom)\"].sort_values()).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Create a trace\n",
    "trace = Scatter(\n",
    "    x = expectedValues,\n",
    "    y = sortedValues,\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "layout = Layout(\n",
    "    title='BD (Prom)',\n",
    "    xaxis=dict(\n",
    "        title='Valor estándar para cuantil exponencial'\n",
    "        \n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Valor obtenido'\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='Comparación con exponencial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Se puede observar que ambas gráficas tienen una forma que podría, de cierta forma, describir a una línea recta, por lo que se puede decir que, en efecto, tienen una distribución siimilar a la exponencial. Sin embargo, es notorio que la variable de BD forma algo similar a una 'S' invertida, lo cual corresponde a una distribución de cola pesada. Si quisieramos compararlo con distribuciones normales, las grficas seran las siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "from scipy.stats import norm\n",
    "\n",
    "expectedValues = pd.Series(range(1 ,R3P_1[\"CPU (Prom)\"].count() + 1)).apply(lambda x: (x - 0.5) / R3P_1[\"CPU (Prom)\"].count()).apply(lambda x: norm.ppf(x))\n",
    "sortedValues = pd.Series(R3P_1[\"CPU (Prom)\"].sort_values()).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Create a trace\n",
    "trace = Scatter(\n",
    "    x = expectedValues,\n",
    "    y = sortedValues,\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "layout = Layout(\n",
    "    title='CPU (Prom)',\n",
    "    xaxis=dict(\n",
    "        title='Valor estándar para cuantil normal'\n",
    "        \n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Valor obtenido'\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='Comparación con normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expectedValues = pd.Series(range(1 ,R3P_1[\"BD (Prom)\"].count() + 1)).apply(lambda x: (x - 0.5) / R3P_1[\"BD (Prom)\"].count()).apply(lambda x: norm.ppf(x))\n",
    "sortedValues = pd.Series(R3P_1[\"BD (Prom)\"].sort_values()).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Create a trace\n",
    "trace = Scatter(\n",
    "    x = expectedValues,\n",
    "    y = sortedValues,\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "layout = Layout(\n",
    "    title='BD (Prom)',\n",
    "    xaxis=dict(\n",
    "        title='Valor estándar para cuantil normal'\n",
    "        \n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Valor obtenido'\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='Comparación con normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Como se puede ver, en vez de parecer líneas rectas, parecen curvas, lo que da a entender que, si lo compararamos con distribuciones normales, serían distribuciones asimétricas, lo cual siguiere que los datos no son \"normales\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oliver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################## CPU ####################\n",
    "# Obtiene el dataframe de excel\n",
    "CPU_File = pd.ExcelFile(\"CPU Prom Trace.xlsx\")\n",
    "CPU_FactorScores = CPU_File.parse(\"Factor Scores\")\n",
    "\n",
    "# Tabla de Factor Scores\n",
    "Factor_Scores = CPU_FactorScores.ix[:8195,:]\n",
    "\n",
    "# Set X\n",
    "X = Factor_Scores.loc[:,'F1'].values\n",
    "X = np.array(X)\n",
    "\n",
    "CPU_EigenValues = CPU_File.parse(\"Eigen values\")\n",
    "LambdaCPU = CPU_EigenValues.iloc[0]['F1']\n",
    "\n",
    "# Medias y desviaciones estandar Originales\n",
    "MediaOriginalCPU = 2323.994\n",
    "desvEstandarCPU = 552.579\n",
    "\n",
    "# Obtiene las Y\n",
    "Y_CPU = (X * desvEstandarCPU) / math.sqrt(LambdaCPU)\n",
    "\n",
    "for x in range(0, np.size(Y_CPU)):\n",
    "    Y_CPU[x] = Y_CPU[x] + MediaOriginalCPU\n",
    "\n",
    "# Saca la media\n",
    "MediaCPU = sum(Y_CPU)/np.size(Y_CPU)\n",
    "\n",
    "# Elimina los negativos\n",
    "Y_CPU = Y_CPU[Y_CPU >= 0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################## BD ###################\n",
    "# Obtiene el dataframe de excel\n",
    "BD_File = pd.ExcelFile(\"DB Prom Trace.xlsx\")\n",
    "BD_FactorScores = BD_File.parse(\"Factor Scores\")\n",
    "\n",
    "# Tabla de Factor Scores\n",
    "Factor_Scores = BD_FactorScores.ix[:8195,:]\n",
    "\n",
    "# Set X\n",
    "X = Factor_Scores.loc[:,'F1'].values\n",
    "X = np.array(X)\n",
    "\n",
    "BD_EigenValues = BD_File.parse(\"Eigen values\")\n",
    "LambdaBD = BD_EigenValues.iloc[0]['F1']\n",
    "\n",
    "# Medias y desviaciones estandar Originales\n",
    "MediaOriginalBD = 5038.738\n",
    "desvEstandarBD = 1771.288\n",
    "\n",
    "# Obtiene las Y\n",
    "Y_BD = (X * desvEstandarBD) / math.sqrt(LambdaBD)\n",
    "\n",
    "for x in range(0, np.size(Y_BD)):\n",
    "    Y_BD[x] = Y_BD[x] + MediaOriginalBD\n",
    "\n",
    "# Saca la media\n",
    "MediaBD = sum(Y_BD)/np.size(Y_BD)\n",
    "\n",
    "# Elimina los negativos\n",
    "Y_BD = Y_BD[Y_BD >= 0] \n",
    "\n",
    "print Y_BD\n",
    "print MediaBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Marco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
